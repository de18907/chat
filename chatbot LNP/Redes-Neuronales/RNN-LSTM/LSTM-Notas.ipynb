{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import random\n",
    "import collections\n",
    "\n",
    "# Parámetros\n",
    "velocidadDeAprendizaje = 0.001\n",
    "numeroDeIteracionesParaElEntrenamiento = 50000\n",
    "iteracionesParaMostrarInfo = 1000\n",
    "numeroDeEntradas = 3\n",
    "\n",
    "# Número de unidades ocultas en una celda RNN\n",
    "numeroDeUnidadesOcultas = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leerDatos(fname):\n",
    "    with open(fname) as f:\n",
    "        contenido = f.readlines() #aquí ss mete cada línea del fichero en una posición del array 'contenido'\n",
    "    contenido = [x.strip() for x in contenido] #aquí cada posición del array 'contenido' se cambia eliminando los espacios en blanco que pudieran hacer al principio y al final de cada línea\n",
    "    contenido = [palabra for i in range(len(contenido)) for palabra in contenido[i].split()] #ahora en cada posición del array 'contenido' se almacena cada palabra de cada línea\n",
    "    contenido = np.array(contenido)\n",
    "    #print(contenido)\n",
    "    return contenido\n",
    "\n",
    "def construirDiccionarios(palabras):\n",
    "    count = collections.Counter(palabras).most_common()\n",
    "    diccionario = dict()\n",
    "    for palabra, _ in count:\n",
    "        diccionario[palabra] = len(diccionario)\n",
    "    diccionarioInverso = dict(zip(diccionario.values(), diccionario.keys()))\n",
    "    return diccionario, diccionarioInverso\n",
    "\n",
    "def RNN(x, pesos, biases):\n",
    "    # redimensionar x a [1, numeroDeEntradas]\n",
    "    x = tf.reshape(x, [-1, numeroDeEntradas])\n",
    "\n",
    "    # Generate a numeroDeEntradas-element sequence of inputs\n",
    "    # (eg. [had] [a] [general] -> [20] [6] [33])\n",
    "    x = tf.split(x,numeroDeEntradas,1)\n",
    "\n",
    "    # LSTM de 2 capas: cada capa tiene un número de unidades ocultas dado por numeroDeUnidadesOcultas.\n",
    "    rnn_cell = rnn.MultiRNNCell([rnn.BasicLSTMCell(numeroDeUnidadesOcultas),rnn.BasicLSTMCell(numeroDeUnidadesOcultas)])\n",
    "\n",
    "    # LSTM de 1 capas: cada capa tiene un número de unidades ocultas dado por numeroDeUnidadesOcultas\n",
    "    # pero tiene una menor \"accuracy\" (precisión).\n",
    "    # Descomentar la línea de abajo para comprobarlo pero comentar las líneas de arriba para el LSTM de 2 capas\n",
    "    # rnn_cell = rnn.BasicLSTMCell(numeroDeUnidadesOcultas)\n",
    "\n",
    "    # Generación de la predicción\n",
    "    outputs, states = rnn.static_rnn(rnn_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Hay tantas salidas como numeroDeEntradas pero sólo nos interesa la última salida\n",
    "    return tf.matmul(outputs[-1], pesos['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------\n",
    "#PREPARACIÓN DE LOS DATOS DE ENTRENAMIENTO\n",
    "\n",
    "ficheroDeEntrenamiento = 'Notas.txt'\n",
    "notasDeEntrenamiento = leerDatos(ficheroDeEntrenamiento)\n",
    "print(\"Notas de entrenamiento cargadas... \")\n",
    "\n",
    "diccionario, diccionarioInverso = construirDiccionarios(notasDeEntrenamiento)\n",
    "print(\"Diccionario <nota,id>:\")\n",
    "print(diccionario)\n",
    "print(\"Diccionario inverso <id,nota>:\")\n",
    "print(diccionarioInverso)\n",
    "totalNotasEnDiccionario = len(diccionario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "#CREACIÓN DEL MODELO DE LA RED NEURONAL\n",
    "\n",
    "tf.reset_default_graph() #limpiamos el graph antes de empezar a añadirle elementos\n",
    "\n",
    "# Definimos la estructura que tendrá el \"graph\" de tensorflow\n",
    "# Un placeholder se usa para indicar que creamos una variable con una determinada estructura a la que le asignaremos valores más tarde\n",
    "# Nos creamos dos variables de tipo placeholder\n",
    "x = tf.placeholder(\"float\", [None, numeroDeEntradas, 1]) # x representará las entradas de la RNN\n",
    "y = tf.placeholder(\"float\", [None, totalNotasEnDiccionario]) # y representará todas las palabras \n",
    "\n",
    "# Pesos y biases de el nodo de salida de la RNN\n",
    "pesos = {\n",
    "    'out': tf.Variable(tf.random_normal([numeroDeUnidadesOcultas, totalNotasEnDiccionario]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([totalNotasEnDiccionario]))\n",
    "}\n",
    "\n",
    "prediccion = RNN(x, pesos, biases)\n",
    "\n",
    "# Indicamos las funciones de \"Loss\" (pérdidas, error) y optimizador del modelo que vamos a usar\n",
    "funcionDeCoste = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediccion, labels=y))\n",
    "optimizador = tf.train.RMSPropOptimizer(learning_rate=velocidadDeAprendizaje).minimize(funcionDeCoste)\n",
    "\n",
    "# Indicamos las funciones de evaluación del modelo que vamos a usar\n",
    "# Ver el siguiente enlace para comprender cómo funciona tf.argmax(XXX,1)\n",
    "# :https://stackoverflow.com/questions/41708572/tensorflow-questions-regarding-tf-argmax-and-tf-equal\n",
    "correct_pred = tf.equal(tf.argmax(prediccion,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32)) #hacemos un cast al tensor correct_pred convirtiéndolo en valores de tipo float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrancamos el \"graph\"\n",
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer()) # Inicialización de las variables\n",
    "    \n",
    "    idIteracion = 0\n",
    "    offset = random.randint(0,numeroDeEntradas+1)\n",
    "    end_offset = numeroDeEntradas + 1\n",
    "    acc_total = 0\n",
    "    loss_total = 0\n",
    "    \n",
    "    #-------------------------------------------------------------\n",
    "    # PROCESO DE APRENDIZAJE\n",
    "    \n",
    "    while idIteracion < numeroDeIteracionesParaElEntrenamiento:\n",
    "        # Asignamos aleatoriamente un offset a partir del cual \n",
    "        # elegiremos un conjunto con Notas consecutivas como numeroDeEntras tengamos.\n",
    "        if offset > (len(notasDeEntrenamiento)-end_offset):\n",
    "            offset = random.randint(0, numeroDeEntradas+1)\n",
    "        # Seleccionamos aleatoriamente un conjunto con tantas Notas consecutivas como numeroDeEntradas\n",
    "        # tengamos para usarlas para indicar a la RNN cuales son las notas \"condicionantes\" o predecesoras\n",
    "        # para obtener la siguiente nota (conscuenciaOnehot)\n",
    "        entradasPredecesoras = [ [diccionario[ str(notasDeEntrenamiento[i])]] for i in range(offset, offset+numeroDeEntradas) ]\n",
    "        # le damos el formato adecuado\n",
    "        entradasPredecesoras = np.reshape(np.array(entradasPredecesoras), [-1, numeroDeEntradas, 1])\n",
    "        \n",
    "        #conscuenciaOnehot indica la palabra que sigue a la secuencia \n",
    "        #(llamémosle \"consecuencia\") dada por entradasPredecesoras\n",
    "        #Empezamos a construir un array tipo \"oneshot\":\n",
    "        #-creo un array inicialmente todo con ceros\n",
    "        conscuenciaOnehot = np.zeros([totalNotasEnDiccionario], dtype=float)\n",
    "        #-pongo un uno en la posición que identifica al id de la Nota en cuestión\n",
    "        conscuenciaOnehot[diccionario[str(notasDeEntrenamiento[offset+numeroDeEntradas])]] = 1.0\n",
    "        #-le damos el formato adecuado: 1 fila, y tantas columnas como sean necesarias\n",
    "        conscuenciaOnehot = np.reshape(conscuenciaOnehot,[1,-1])\n",
    "        \n",
    "        #REALIZAMOS EL APRENDIZAJE\n",
    "        _, acc, loss, prob_notaSiguiente_pred = session.run([optimizador, accuracy, funcionDeCoste, prediccion], \\\n",
    "                                                feed_dict={x: entradasPredecesoras, y: conscuenciaOnehot})\n",
    "        loss_total += loss\n",
    "        acc_total += acc\n",
    "        \n",
    "        #Cada iteracionesParaMostrarInfo se muestra información sobre el estado del aprendizaje\n",
    "        if (idIteracion+1) % iteracionesParaMostrarInfo == 0:\n",
    "            print(\"Iteración= \" + str(idIteracion+1) + \", Loss media= \" + \\\n",
    "                  \"{:.6f}\".format(loss_total/iteracionesParaMostrarInfo) + \", Accuracy media= \" + \\\n",
    "                  \"{:.2f}%\".format(100*acc_total/iteracionesParaMostrarInfo))\n",
    "            acc_total = 0\n",
    "            loss_total = 0\n",
    "            #se toman las Notas de entrenamiento (tantas como entradas tenga nuestra LSTM)\n",
    "            #a partir de una posición dentro del array \"NotasDeEntrenamiento\" dada por el offset\n",
    "            notasPredecesoras = [notasDeEntrenamiento[i] for i in range(offset, offset + numeroDeEntradas)] \n",
    "            #cogemos el último elemento del array \"NotasDeEntrenamiento\" para el offset dado\n",
    "            #este elemento debería corresponderse con la salida predicha (prob_notaSiguiente_pred)\n",
    "            notaSiguiente = notasDeEntrenamiento[offset + numeroDeEntradas]\n",
    "            #con el diccionario inverso obtenemos la Nota que se correspondería con el código \"onehot\" de la Nota predicha\n",
    "            notaSiguiente_pred = diccionarioInverso[int(tf.argmax(prob_notaSiguiente_pred, 1).eval())]\n",
    "            print(\"%s - [%s] vs [%s]\" % (notasPredecesoras,notaSiguiente,notaSiguiente_pred))\n",
    "            \n",
    "        idIteracion += 1\n",
    "        offset += (numeroDeEntradas+1)\n",
    "    print(\"Optimización acabada!\")\n",
    "    \n",
    "    #-------------------------------------------------------------\n",
    "    # COMPROBACIÓN DEL APRENDIZAJE\n",
    "    \n",
    "    #Número de Notas consecutivas que generará la RNN\n",
    "    #es decir, la longitud del texto que deberá crear la RNN, expresada en número de Notas\n",
    "    numeroDeNotasEncadenadasAgenerar=32\n",
    "    \n",
    "    while True:\n",
    "        #preparo una variable con el mensaje para pedir Notas\n",
    "        varSecuenciaAprobar = \"Escriba %s Notas: \" % numeroDeEntradas \n",
    "        secuenciaAprobrar = input(varSecuenciaAprobar)\n",
    "        #una vez tomada la secuenciaAprobrar, se le quitan los espacios en blanco que pueda haber al principio y al final de la secuenciaAprobrar\n",
    "        secuenciaAprobrar = secuenciaAprobrar.strip()\n",
    "        #se trocea la secuenciaAprobrar rompiéndola por los espacios en blanco, obteniendo sólo la lista de Notas que la contienen\n",
    "        NotasDeLaSecuenciaAprobrar = secuenciaAprobrar.split(' ')\n",
    "        #Si el número de Notas del mensaje introducido no se corresponde con el número de entradas de la RNN\n",
    "        #se salta el resto del código y, por tanto, se volverá a pedir que se escriban las Notas\n",
    "        if len(NotasDeLaSecuenciaAprobrar) != numeroDeEntradas:\n",
    "            continue\n",
    "        \n",
    "        siguienteNotaPredicha=\"\"\n",
    "        melodiaGenerada=\"\"\n",
    "        \n",
    "        try:\n",
    "            entradasPredecesoras = [diccionario[str(NotasDeLaSecuenciaAprobrar[i])] for i in range(len(NotasDeLaSecuenciaAprobrar))]\n",
    "            for i in range(numeroDeNotasEncadenadasAgenerar):\n",
    "                notasPrevias = np.reshape(np.array(entradasPredecesoras), [-1, numeroDeEntradas, 1])\n",
    "                #se obtiene la salida predicha (en formato \"probabilistico\") para las Notas dadas\n",
    "                prob_notaSiguiente_pred = session.run(prediccion, feed_dict={x: notasPrevias})\n",
    "                #convertimos el código \"onehot\" en su número correspondiente\n",
    "                onehot_notaSiguiente_pred_id = int(tf.argmax(prob_notaSiguiente_pred, 1).eval()) \n",
    "                siguienteNotaPredicha = diccionarioInverso[onehot_notaSiguiente_pred_id]\n",
    "                #la melodia generada será la Nota predicha anterior añadiéndole la nueva Nota predicha\n",
    "                melodiaGenerada = \"%s %s\" % (melodiaGenerada,siguienteNotaPredicha)\n",
    "                #quito la primnera Nota\n",
    "                entradasPredecesoras = entradasPredecesoras[1:]\n",
    "                #Añadimos el código \"onehot\" de la Nota predicha al final del array \"entradasPredecesoras\"\n",
    "                entradasPredecesoras.append(onehot_notaSiguiente_pred_id)\n",
    "            print(melodiaGenerada)\n",
    "        except:\n",
    "            print(\"Una Nota no está en el diccionario\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
