{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import random\n",
    "import collections\n",
    "\n",
    "# Parámetros\n",
    "velocidadDeAprendizaje = 0.001\n",
    "numeroDeIteracionesParaElEntrenamiento = 50000\n",
    "iteracionesParaMostrarInfo = 1000\n",
    "numeroDeEntradas = 3\n",
    "\n",
    "# Número de unidades ocultas en una celda RNN\n",
    "numeroDeUnidadesOcultas = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leerDatos(fname):\n",
    "    with open(fname) as f:\n",
    "        contenido = f.readlines() #aquí se mete cada línea del fichero en una posición del array 'contenido'\n",
    "    #aquí cada posición del array 'contenido' se cambia eliminando los espacios en blanco que pudieran haber al principio y al final de cada línea\n",
    "    contenido = [x.strip() for x in contenido]\n",
    "    #ahora en cada posición del array 'contenido' se almacena cada palabra de cada línea\n",
    "    contenido = [palabra for i in range(len(contenido)) for palabra in contenido[i].split()] \n",
    "    contenido = np.array(contenido)\n",
    "    #print(contenido)\n",
    "    return contenido\n",
    "\n",
    "def construirDiccionarios(palabras):\n",
    "    count = collections.Counter(palabras).most_common()\n",
    "    diccionario = dict()\n",
    "    for palabra, _ in count:\n",
    "        diccionario[palabra] = len(diccionario)\n",
    "    diccionarioInverso = dict(zip(diccionario.values(), diccionario.keys()))\n",
    "    return diccionario, diccionarioInverso\n",
    "\n",
    "#predictor\n",
    "def RNN(x, pesos, biases):\n",
    "    # redimensionar x a [1, numeroDeEntradas]\n",
    "    x = tf.reshape(x, [-1, numeroDeEntradas])\n",
    "    x = tf.split(x,numeroDeEntradas,1)\n",
    "\n",
    "    # LSTM de 2 capas: cada capa tiene un número de unidades ocultas dado por numeroDeUnidadesOcultas.\n",
    "    rnn_cell = rnn.MultiRNNCell([rnn.BasicLSTMCell(numeroDeUnidadesOcultas),rnn.BasicLSTMCell(numeroDeUnidadesOcultas)])\n",
    "\n",
    "    # LSTM de 1 capa: cada capa tiene un número de unidades ocultas dado por numeroDeUnidadesOcultas\n",
    "    # pero tiene una menor \"accuracy\" (precisión).\n",
    "    # Descomentar la línea de abajo para comprobarlo pero comentar las líneas de arriba para el LSTM de 2 capas\n",
    "    # rnn_cell = rnn.BasicLSTMCell(numeroDeUnidadesOcultas)\n",
    "\n",
    "    # Generación de la predicción\n",
    "    outputs, states = rnn.static_rnn(rnn_cell, x, dtype=tf.float32) \n",
    "    #outputs=[]1 x numeroDeUnidadesOcultas\n",
    "    #pesos=[]numeroDeUnidadesOcultas x totalPalabrasEnDiccionario\n",
    "    #biases=[]1 x totalPalabrasEnDiccionario\n",
    "    # Hay tantas salidas como numeroDeEntradas pero sólo nos interesa la última salida\n",
    "    return tf.matmul(outputs[-1], pesos['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras de entrenamiento cargadas... \n",
      "Diccionario <palabra,id>:\n",
      "{'chao!': 64, 'todo': 12, 'contarme?': 65, 'eches': 66, 'resulta': 67, 'de': 7, 'la': 18, 'poco.': 13, 'vaya': 68, 'bien!': 69, 'tenido': 70, 'tu?': 21, 'eso.': 71, 'sabes,': 34, 'hace': 73, 'vale,': 74, 'estaba': 75, 'chismoso': 76, 'bien?': 77, 'bronca.': 78, 'quiza,': 79, 'contarlas': 80, 'seguimos': 81, 'sonado': 83, 'hoy': 84, 'notado': 85, 'voy': 86, 'poco': 35, 'ya': 14, 'ti.': 36, 'molesta': 87, 'curioso': 89, 'contare': 90, 'raro.': 91, 'hola.': 92, 'ambiente.': 82, 'eso,': 94, 'tengo': 37, 'que': 0, 'realidad.': 96, 'muy': 201, 'animado.': 88, 'muchas': 98, 'mal.': 38, 'llamas?': 100, 'sinceramente?': 101, 'sin': 102, 'culpa,': 103, 'yo.': 104, 'cuentame.': 105, 'veras,': 106, 'has': 107, 'tiempo.': 99, 'vamos,': 108, 'quiero': 109, 'pues': 26, 'si.': 17, 'entonces': 15, 'pasado': 110, 'diria': 40, 'quejar.': 111, 'solo': 41, 'ok.': 42, 'mundo.': 112, 'han': 113, 'maÃ±ana.': 114, 'llevas': 115, 'o': 116, 'algo.': 22, 'tarde': 219, 'hecho': 43, 'no,': 117, 'bueno.': 118, 'soy,': 119, 'quieras.': 120, 'mas': 32, 'maÃ±ana,': 176, 'podria': 121, 'ver,': 122, 'hombre,': 44, 'va': 124, 'dice.': 125, 'entiendo': 123, 'aburrido': 126, 'hablando,': 127, 'nada.': 45, 'contendre': 128, 'contencion': 129, 'cosa': 130, 'contigo': 131, 'robot?': 132, 'y': 10, 'razon.': 133, 'bit.': 134, '...': 135, 'podido': 136, 'tiempo': 137, 'secreto?': 138, 'puedo': 57, 'ir': 139, 'cuentame': 200, 'una': 24, 'dime': 140, 'maÃ±ana': 141, 'novedades.': 142, 'claro.': 143, 'estas?': 144, 'debia.': 145, 'subido': 95, 'buenas': 146, 'por': 46, 'tal': 47, 'tu': 147, 'lo': 1, 'alguien': 49, 'tan': 148, 'a': 5, 'bien.': 50, 'gracioso!': 149, 'paredes.': 150, 'malo.': 151, 'sueldo!': 152, 'robot': 153, 'se': 25, 'mismo': 154, 'tienes': 39, 'veo,': 155, 'claro,': 182, 'bien,': 183, 'bueno,': 19, 'cierto,': 209, 'robot.': 195, 'vaya,': 52, 'ya.': 157, 'nada': 158, 'perfecto.': 159, 'tampoco': 160, 'normal,': 161, 'mucho': 162, 'es': 3, 'se,': 163, 'irme.': 164, 'persona.': 165, 'dejo.': 166, 'verdad?': 167, 'discrecion': 168, 'acuerdo.': 169, 'mala.': 170, 'jejeje.': 171, 'vale.': 53, 'tirando.': 172, 'faltado': 173, 'puedes': 174, 'ya?': 54, 'porque?': 175, 'quien': 177, 'eso': 55, 'amigos.': 178, 'no?': 56, 'me': 8, 'soy': 179, 'nombre.': 222, 'ya,': 27, 'en': 180, 'esplendido.': 181, 'normal.': 51, 'ahi': 156, 'gracias.': 59, 'contado': 184, 'siento.': 185, 'veo': 186, 'contarselo': 28, 'hablar': 60, 'verdad': 187, 'no': 4, 'dia?': 188, 'suena': 189, 'eres!': 190, 'jeje,': 191, 'pero': 9, 'tela.': 192, 'con': 193, 'noticias': 194, 'hasta': 58, 'preguntas?': 196, 'esperando': 197, 'si?': 198, 'algo': 199, 'noticia': 93, 'noche.': 97, 'pasado?': 202, 'aprender': 203, 'nombre': 204, 'mas?': 205, 'desde': 206, 'las': 61, 'porque': 29, '.': 207, 'siempre.': 30, 'no.': 208, 'bien': 72, 'hay': 210, 'un': 2, 'mejor.': 211, 'dia': 212, 'tus': 213, 'como': 20, 'vale?': 214, 'eso?': 215, 'general,': 216, 'el': 31, 'buena': 62, 'ha': 11, 'vendria': 217, 'animar': 218, 'he': 16, 'si,': 23, 'pases': 220, 'igualmente.': 221, 'yo': 48, 'cenar.': 223, 'para': 33, 'entiende': 224, 'eres': 63, 'alegro': 225, 'te': 6}\n",
      "Diccionario inverso <id,palabra>:\n",
      "{0: 'que', 1: 'lo', 2: 'un', 3: 'es', 4: 'no', 5: 'a', 6: 'te', 7: 'de', 8: 'me', 9: 'pero', 10: 'y', 11: 'ha', 12: 'todo', 13: 'poco.', 14: 'ya', 15: 'entonces', 16: 'he', 17: 'si.', 18: 'la', 19: 'bueno,', 20: 'como', 21: 'tu?', 22: 'algo.', 23: 'si,', 24: 'una', 25: 'se', 26: 'pues', 27: 'ya,', 28: 'contarselo', 29: 'porque', 30: 'siempre.', 31: 'el', 32: 'mas', 33: 'para', 34: 'sabes,', 35: 'poco', 36: 'ti.', 37: 'tengo', 38: 'mal.', 39: 'tienes', 40: 'diria', 41: 'solo', 42: 'ok.', 43: 'hecho', 44: 'hombre,', 45: 'nada.', 46: 'por', 47: 'tal', 48: 'yo', 49: 'alguien', 50: 'bien.', 51: 'normal.', 52: 'vaya,', 53: 'vale.', 54: 'ya?', 55: 'eso', 56: 'no?', 57: 'puedo', 58: 'hasta', 59: 'gracias.', 60: 'hablar', 61: 'las', 62: 'buena', 63: 'eres', 64: 'chao!', 65: 'contarme?', 66: 'eches', 67: 'resulta', 68: 'vaya', 69: 'bien!', 70: 'tenido', 71: 'eso.', 72: 'bien', 73: 'hace', 74: 'vale,', 75: 'estaba', 76: 'chismoso', 77: 'bien?', 78: 'bronca.', 79: 'quiza,', 80: 'contarlas', 81: 'seguimos', 82: 'ambiente.', 83: 'sonado', 84: 'hoy', 85: 'notado', 86: 'voy', 87: 'molesta', 88: 'animado.', 89: 'curioso', 90: 'contare', 91: 'raro.', 92: 'hola.', 93: 'noticia', 94: 'eso,', 95: 'subido', 96: 'realidad.', 97: 'noche.', 98: 'muchas', 99: 'tiempo.', 100: 'llamas?', 101: 'sinceramente?', 102: 'sin', 103: 'culpa,', 104: 'yo.', 105: 'cuentame.', 106: 'veras,', 107: 'has', 108: 'vamos,', 109: 'quiero', 110: 'pasado', 111: 'quejar.', 112: 'mundo.', 113: 'han', 114: 'maÃ±ana.', 115: 'llevas', 116: 'o', 117: 'no,', 118: 'bueno.', 119: 'soy,', 120: 'quieras.', 121: 'podria', 122: 'ver,', 123: 'entiendo', 124: 'va', 125: 'dice.', 126: 'aburrido', 127: 'hablando,', 128: 'contendre', 129: 'contencion', 130: 'cosa', 131: 'contigo', 132: 'robot?', 133: 'razon.', 134: 'bit.', 135: '...', 136: 'podido', 137: 'tiempo', 138: 'secreto?', 139: 'ir', 140: 'dime', 141: 'maÃ±ana', 142: 'novedades.', 143: 'claro.', 144: 'estas?', 145: 'debia.', 146: 'buenas', 147: 'tu', 148: 'tan', 149: 'gracioso!', 150: 'paredes.', 151: 'malo.', 152: 'sueldo!', 153: 'robot', 154: 'mismo', 155: 'veo,', 156: 'ahi', 157: 'ya.', 158: 'nada', 159: 'perfecto.', 160: 'tampoco', 161: 'normal,', 162: 'mucho', 163: 'se,', 164: 'irme.', 165: 'persona.', 166: 'dejo.', 167: 'verdad?', 168: 'discrecion', 169: 'acuerdo.', 170: 'mala.', 171: 'jejeje.', 172: 'tirando.', 173: 'faltado', 174: 'puedes', 175: 'porque?', 176: 'maÃ±ana,', 177: 'quien', 178: 'amigos.', 179: 'soy', 180: 'en', 181: 'esplendido.', 182: 'claro,', 183: 'bien,', 184: 'contado', 185: 'siento.', 186: 'veo', 187: 'verdad', 188: 'dia?', 189: 'suena', 190: 'eres!', 191: 'jeje,', 192: 'tela.', 193: 'con', 194: 'noticias', 195: 'robot.', 196: 'preguntas?', 197: 'esperando', 198: 'si?', 199: 'algo', 200: 'cuentame', 201: 'muy', 202: 'pasado?', 203: 'aprender', 204: 'nombre', 205: 'mas?', 206: 'desde', 207: '.', 208: 'no.', 209: 'cierto,', 210: 'hay', 211: 'mejor.', 212: 'dia', 213: 'tus', 214: 'vale?', 215: 'eso?', 216: 'general,', 217: 'vendria', 218: 'animar', 219: 'tarde', 220: 'pases', 221: 'igualmente.', 222: 'nombre.', 223: 'cenar.', 224: 'entiende', 225: 'alegro'}\n"
     ]
    }
   ],
   "source": [
    "#-----------------------------------------\n",
    "#PREPARACIÓN DE LOS DATOS DE ENTRENAMIENTO\n",
    "\n",
    "ficheroDeEntrenamiento = 'TextoDeEntrenamiento.txt' #Gramatica.txt ó ControlRobot.txt ó TextoDeEntrenamiento.txt\n",
    "palabrasDeEntrenamiento = leerDatos(ficheroDeEntrenamiento)\n",
    "print(\"Palabras de entrenamiento cargadas... \")\n",
    "\n",
    "diccionario, diccionarioInverso = construirDiccionarios(palabrasDeEntrenamiento)\n",
    "print(\"Diccionario <palabra,id>:\")\n",
    "print(diccionario)\n",
    "print(\"Diccionario inverso <id,palabra>:\")\n",
    "print(diccionarioInverso)\n",
    "totalPalabrasEnDiccionario = len(diccionario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "#CREACIÓN DEL MODELO DE LA RED NEURONAL\n",
    "\n",
    "tf.reset_default_graph() #limpiamos el graph antes de empezar a añadirle elementos\n",
    "\n",
    "# Definimos la estructura que tendrá el \"graph\" de tensorflow\n",
    "\n",
    "# Un placeholder se usa para indicar que creamos una variable con una determinada estructura a la que le asignaremos valores más tarde\n",
    "# Nos creamos dos variables de tipo placeholder\n",
    "# \"None\" se usa para reajustar el tamaño del array automaticamente según las necesidades específicas del código\n",
    "# \"None\" significa que se puede entrenar la red con cualquier número de ejemplos\n",
    "x = tf.placeholder(\"float\", [None, numeroDeEntradas, 1]) # x representará las entradas de la RNN. \n",
    "y = tf.placeholder(\"float\", [None, totalPalabrasEnDiccionario]) # y representará todas las palabras \n",
    "\n",
    "# Pesos y biases de el nodo de salida de la RNN\n",
    "pesos = { #pesos=[]numeroDeUnidadesOcultas x totalPalabrasEnDiccionario\n",
    "    'out': tf.Variable(tf.random_normal([numeroDeUnidadesOcultas, totalPalabrasEnDiccionario]))\n",
    "}\n",
    "biases = { #biases=[]1 x totalPalabrasEnDiccionario\n",
    "    'out': tf.Variable(tf.random_normal([totalPalabrasEnDiccionario]))\n",
    "}\n",
    "\n",
    "prediccion = RNN(x, pesos, biases) #prediccion=[]1 x totalPalabrasEnDiccionario\n",
    "\n",
    "# Indicamos las funciones de \"Loss\" (pérdidas, error) y optimizador del modelo que vamos a usar\n",
    "funcionDeCoste = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediccion, labels=y))\n",
    "optimizador = tf.train.RMSPropOptimizer(learning_rate=velocidadDeAprendizaje).minimize(funcionDeCoste)\n",
    "\n",
    "# Indicamos las funciones de evaluación del modelo que vamos a usar\n",
    "# Ver el siguiente enlace para comprender cómo funciona tf.argmax(XXX,1)\n",
    "# https://stackoverflow.com/questions/41708572/tensorflow-questions-regarding-tf-argmax-and-tf-equal\n",
    "\n",
    "#correct_pred contiene un array con valores 1 allí donde tf.argmax(prediccion,1) y tf.argmax(y,1) tienen el mismo valor\n",
    "correct_pred = tf.equal(tf.argmax(prediccion,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32)) #hacemos un cast al tensor correct_pred convirtiéndolo en valores de tipo float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrancamos el \"graph\"\n",
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer()) # Inicialización de las variables\n",
    "    \n",
    "    idIteracion = 0\n",
    "    offset = random.randint(0,numeroDeEntradas+1)\n",
    "    end_offset = numeroDeEntradas + 1\n",
    "    acc_total = 0\n",
    "    loss_total = 0\n",
    "    \n",
    "    #-------------------------------------------------------------\n",
    "    # PROCESO DE APRENDIZAJE\n",
    "    \n",
    "    while idIteracion < numeroDeIteracionesParaElEntrenamiento:\n",
    "        # Asignamos aleatoriamente un offset a partir del cual \n",
    "        # elegiremos un conjunto con palabras consecutivas como numeroDeEntras tengamos.\n",
    "        if offset > (len(palabrasDeEntrenamiento)-end_offset):\n",
    "            offset = random.randint(0, numeroDeEntradas+1)\n",
    "        # Seleccionamos aleatoriamente un conjunto con tantas palabras consecutivas como numeroDeEntradas \n",
    "        # tengamos para usarlas para indicar a la RNN cuales son las palabras \"condicionantes\" o predecesoras\n",
    "        # para obtener la siguiente palabra (conscuenciaOnehot)\n",
    "        entradasPredecesoras = [ [diccionario[ str(palabrasDeEntrenamiento[i])]] for i in range(offset, offset+numeroDeEntradas) ]\n",
    "        # le damos el formato adecuado\n",
    "        entradasPredecesoras = np.reshape(np.array(entradasPredecesoras), [-1, numeroDeEntradas, 1])\n",
    "        \n",
    "        #conscuenciaOnehot indica la palabra que sigue a la secuencia \n",
    "        #(llamémosle \"consecuencia\") dada por entradasPredecesoras\n",
    "        #Empezamos a construir un array tipo \"oneshot\":\n",
    "        #-creo un array inicialmente todo con ceros\n",
    "        conscuenciaOnehot = np.zeros([totalPalabrasEnDiccionario], dtype=float)\n",
    "        #-pongo un uno en la posición que identifica al id de la palabra en cuestión\n",
    "        conscuenciaOnehot[diccionario[str(palabrasDeEntrenamiento[offset+numeroDeEntradas])]] = 1.0\n",
    "        #-le damos el formato adecuado: 1 fila, y tantas columnas como sean necesarias\n",
    "        conscuenciaOnehot = np.reshape(conscuenciaOnehot,[1,-1])\n",
    "        \n",
    "        #REALIZAMOS EL APRENDIZAJE\n",
    "        _, acc, loss, prob_palabraSiguiente_pred = session.run([optimizador, accuracy, funcionDeCoste, prediccion], \\\n",
    "                                                feed_dict={x: entradasPredecesoras, y: conscuenciaOnehot})\n",
    "        loss_total += loss\n",
    "        acc_total += acc\n",
    "        \n",
    "        #Cada iteracionesParaMostrarInfo se muestra información sobre el estado del aprendizaje\n",
    "        if (idIteracion+1) % iteracionesParaMostrarInfo == 0:\n",
    "            print(\"Iteración= \" + str(idIteracion+1) + \", Loss media= \" + \\\n",
    "                  \"{:.6f}\".format(loss_total/iteracionesParaMostrarInfo) + \", Accuracy media= \" + \\\n",
    "                  \"{:.2f}%\".format(100*acc_total/iteracionesParaMostrarInfo))\n",
    "            acc_total = 0\n",
    "            loss_total = 0\n",
    "            #se toman las palabras de entrenamiento (tantas como entradas tenga nuestra LSTM)\n",
    "            #a partir de una posición dentro del array \"palabrasDeEntrenamiento\" dada por el offset\n",
    "            palabrasPredecesoras = [palabrasDeEntrenamiento[i] for i in range(offset, offset + numeroDeEntradas)] \n",
    "            #cogemos el último elemento del array \"palabrasDeEntrenamiento\" para el offset dado\n",
    "            #este elemento debería corresponderse con la salida predicha (prob_palabraSiguiente_pred)\n",
    "            palabraSiguiente = palabrasDeEntrenamiento[offset + numeroDeEntradas]\n",
    "            #con el diccionario inverso obtenemos la palabra que se correspondería con el código \"onehot\" de la palabra predicha\n",
    "            palabraSiguiente_pred = diccionarioInverso[int(tf.argmax(prob_palabraSiguiente_pred, 1).eval())]\n",
    "            print(\"%s - [%s] vs [%s]\" % (palabrasPredecesoras,palabraSiguiente,palabraSiguiente_pred))\n",
    "            \n",
    "        idIteracion += 1\n",
    "        offset += (numeroDeEntradas+1)\n",
    "    print(\"Optimización acabada!\")\n",
    "    \n",
    "    #-------------------------------------------------------------\n",
    "    # COMPROBACIÓN DEL APRENDIZAJE\n",
    "    \n",
    "    #Número de palabras consecutivas que generará la RNN\n",
    "    #es decir, la longitud del texto que deberá crear la RNN, expresada en número de palabras\n",
    "    #numeroDePalabrasEncadenadasAgenerar=32\n",
    "    \n",
    "    while True:\n",
    "        #preparo una variable con el mensaje para pedir palabras\n",
    "        varSecuenciaAprobar = \"Escriba %s palabras: \" % numeroDeEntradas \n",
    "        secuenciaAprobrar = input(varSecuenciaAprobar)\n",
    "        #una vez tomada la secuenciaAprobrar, se le quitan los espacios en blanco que pueda haber al principio y al final de la secuenciaAprobrar\n",
    "        secuenciaAprobrar = secuenciaAprobrar.strip()\n",
    "        #se trocea la secuenciaAprobrar rompiéndola por los espacios en blanco, obteniendo sólo la lista de palabras que la contienen\n",
    "        palabrasDeLaSecuenciaAprobrar = secuenciaAprobrar.split(' ')\n",
    "        #Si el número de palabras del mensaje introducido no se corresponde con el número de entradas de la RNN\n",
    "        #se salta el resto del código y, por tanto, se volverá a pedir que se escriban las palabras\n",
    "        #if len(palabrasDeLaSecuenciaAprobrar) != numeroDeEntradas:\n",
    "        #    continue\n",
    "        \n",
    "        #Completo la secuencia introducida, insertando . antes de ella hasta completar un total de numeroDeEntradas palabras\n",
    "        while len(palabrasDeLaSecuenciaAprobrar) <= numeroDeEntradas:\n",
    "            palabrasDeLaSecuenciaAprobrar.insert(0,\". \")\n",
    "        \n",
    "        #Si la secuencia introducida tiene más de numeroDeEntradas palabras, voy quitando las del principio\n",
    "        while len(palabrasDeLaSecuenciaAprobrar) > numeroDeEntradas:\n",
    "            palabrasDeLaSecuenciaAprobrar.pop(0)\n",
    "        \n",
    "        siguientePalabraPredicha=\"\"\n",
    "        fraseGenerada=\"\"\n",
    "        \n",
    "        try:\n",
    "            entradasPredecesoras = [diccionario[str(palabrasDeLaSecuenciaAprobrar[i])] for i in range(len(palabrasDeLaSecuenciaAprobrar))]\n",
    "            #for i in range(numeroDePalabrasEncadenadasAgenerar):\n",
    "            while (\".\" not in siguientePalabraPredicha) and (\"?\" not in siguientePalabraPredicha):\n",
    "                palabrasPrevias = np.reshape(np.array(entradasPredecesoras), [-1, numeroDeEntradas, 1])\n",
    "                #se obtiene la salida predicha (en formato \"probabilistico\") para las palabras dadas\n",
    "                prob_palabraSiguiente_pred = session.run(prediccion, feed_dict={x: palabrasPrevias})\n",
    "                #convertimos prob_palabraSiguiente_pred en su número de palabra correspondiente\n",
    "                #buscando la posición del valor máximo dentro del vector\n",
    "                palabraSiguiente_pred_id = int(tf.argmax(prob_palabraSiguiente_pred, 1).eval()) \n",
    "                siguientePalabraPredicha = diccionarioInverso[palabraSiguiente_pred_id]\n",
    "                #la frase generada será la palabra predicha anterior añadiéndole la nueva palabra predicha\n",
    "                fraseGenerada = \"%s %s\" % (fraseGenerada,siguientePalabraPredicha)\n",
    "                #quito la primnera palabra\n",
    "                entradasPredecesoras = entradasPredecesoras[1:]\n",
    "                #Añadimos el código \"onehot\" de la palabra predicha al final del array \"entradasPredecesoras\"\n",
    "                entradasPredecesoras.append(palabraSiguiente_pred_id)\n",
    "            print(fraseGenerada)\n",
    "        except:\n",
    "            print(\"Una palabra no está en el diccionario\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
